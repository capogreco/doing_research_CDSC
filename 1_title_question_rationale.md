---
bibliography: bibliography.bib
indent: true
---

# Distributing Synthesis Across Audiences' Phones

## Background Information

For those who are unfamiliar with the field of contemporary computer music, perhaps the most efficient way to understand the proposed research project, which seeks to instantiate *distributed synthesis* (the coalescing of audiences' personal devices into a single, conglomerated musical instrument) as a creative practice that draws from, and contributes to, the fields of music, art, technology, and education; might be to understand how *live coding*, the creative practice of writing code "on-the-fly" as a form of expressive musical performance, [@collinsLiveCodingLaptop2003; @wang2004OntheFlyProgramming2017] implicitly functions as a *boundary object* [@lovelessHowMakeArt2019] capable of doing exactly each of these things.

As a musical practice, *live coding* invites practitioners to interface with the computational and transducing (i.e. loudspeaker) capacities of some technological assemblage (in most cases - a computer and a public address system) via the affordances of a text-based computer language, as written and executed from within some form of integrated development environment.  Here we can see *live coding* draw from the conventions of electronic music performance and algorithmic music composition, and contribute a repertoire fabricated largely from materials brokered from an adjacent community of practice - the field of computer programming.  From the perspective of education, *live coding* cultivates an intrinsically motivated pathway into the study of computer science by instantiating a culturally visible practice of computer programming which elevates the status of digital literacy.

In each discipline (i.e. both music, and computer programming), the appearance of *live coding* poses some threat to the presiding primeval sense of correctness - an agitation that produces a set of tensions that require some amount of intra-disciplinary discourse to explicate.  This drive to explication generates a new vocabulary capable of attending to those novel tensions, and a set of central problematics are instantiated.  Via these central problematics, what was initially an uncanny boundary object is able to become intelligible as a practice within the field.  Because of these transversal, defamiliarising, discursive effects, we can understand *live coding* to bear some affinity with the body of work in contemporary art that deals with post-relational, ecological aesthetics. [@lovelessRelationalEcologicalForm2022]

It is in these ways, that the project of *distributed synthesis* wishes to follow in the footsteps of *live coding*, but with some important differences.  While both projects broker repertoire from the field of computer programming, in *distributed synthesis*, the technological assemblages being interfaced with are sets of smartphones (or other personal devices), which immediately presents a different set of problems and opportunities, not least of which being *how to harness the computational and transducing capacities of smartphones*, and *how to connect them together*.

This research investigates the creative and theoretical ramifications of using the internet browser and its set of application programming interfaces to commandeer phones' technological affordances, and of using the set of pre-existing internet communication protocols to solve the problem of coordination.  As such, unlike *live coding*, the type of *distributed synthesis* advocated for in this research draws a significant portion of its technical knowledge from *web development*, a move that comes with its own set of interesting implications and agitations, both for computer music, and web development.

There is an important sense in which *distributed synthesis* might be an even more ambitious undertaking than *live coding*, which has to do with what it is asking from audience members.  Although *live-coding* may be stylistically challenging, with performances tending to be long-form, meandering, repetative, etc., the material coordinates of the music performance ritual are largely unchanged.  With *distributed synthesis*, however, even before the *stylistic* constraints necessitated by the limitations of the technological assemblage become a factor, a different set of problems and opportunities, which arise in relation to what material coordinates constitute the music performance ritual in the first place, must be grappled with.  The problematics around assembly and ritual arise in relation to this fundamental agitation - that, if, *conceptually*, we are to coalesce our phones into one conglomerated musical instrument, what ought we to do with our phones, *physically*?

Finally, we might note that the compositional problematics of *live coding*, which must scaffold for the limitations of a purely text-based performance interface, differ substantially from those of *distributed synthesis*, for which the performance interface is not specified, and for which the central compositional problematics instead focus on how to scaffold for the limitations in timing necessitated by latencies in client / server / database communications; and how to best make use of the potential for massive polyphony uniquely present in *distributed synthesis* situations.

## Research Questions

- What are the central problematics of distributed synthesis:
  - for music?
  - for computer programming?
- What approaches to digital music instrument design can:
  - compensate for the limitations of distributed synthesis?
  - harness its potential for massive polyphony?
- What ought to be done with the phones, physically, in the context of the musicking ritual?

## Rationale

In addition to being a creative coding project [@maedaCreativeCode2004] situated in the critical posthumanities [@braidottiTheoreticalFrameworkCritical2019], *distributed synthesis* institutes a form of creativity in which the practioner works with the materials that constitute the internet - that place where we spend an increasing amount of our lives.  We can invoke here a parallel with a violin-maker that must feel the grain of the timber they are working with in order to understand the optimal way to put the instrument together.  The relationship the violin-maker has with the wood is *sensual* - by feeling the *texture* of the material [@sedgwickTouchingFeelingAffect2003], already the violin-maker is thinking about its *affordances*.  Similarly, a practitioner of *distributed synthesis* must feel the material of the internet - the servers, databases, satillites, phones, browsers, etc. - for its *texture*.

In this sense, *distributed synthesis* inherits something from *glitch* - a praxis that not only deepens our technical understanding of the technology we use all the time, but reorients our fundamental assumptions about what we can do with technology, and ultimately, whose benefit it exists *for*. [@menkmanGlitchMomentUm2011]  This reorientation, which implicitly elevates the norm of digital literacy, and which cultivates communities' technology generating capacities, would be making a timely appearance on the cultural stage in the context of widening wealth inequality under emergent forms of technological oppression [@warkCapitalDeadThis2021; @varoufakisTechnofeudalismWhatKilled2023; @doctorowInternetConHow2023].

# Skills Required

In addition to the skills required for the reading and writing, literature review, citation management, note-taking, and knowledge management aspects of doing research in general, this project combines of number of technical knowledge sets.

## Research Skills

### Reading

For reading, I am using a system of stapled A4-sized print-outs, books, as well as reading done on the screen.  Time is allocated to reading, as well as interstitial, opportunistic reading, such as on public transport, and during wait times.  My current reading skills and systems ought to be adequate for the requirements of this research project.

### Note-taking

I take notes firstly on the physical paper, by underlining with a 3B 0.5mm mechanical pencil and a small ruler or bookmark, and making physical annotations in the margins.  Then I copy and expand those notes in [Obsidian](https://obsidian.md/) - a markdown-oriented writing and knowledge management software.  I also have a physical notebook for capturing ideas, writing to-do lists, etc.  My current note-taking system has been holding up so far and I think should be up to the task of this PhD research project.


### Writing

I leave technical breadcrumbs on my blog [distributing-synthesis.fm](https://distributing-synthesis.fm), which I write in markdown, and upload via [Github](https://github.com), and [Deno Deploy](https://deno.com/deploy).  I write my academic writing as markdown in [Visual Studio Code](https://code.visualstudio.com/), and then use [Pandoc](https://pandoc.org/) to render it to portable document format.

### Citation Management

I use [Zotero](https://www.zotero.org/), replete with [browser](https://www.zotero.org/download/connectors) and [Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=mblode.zotero) extensions, to organise and render my citations automatically.  The system has been working well, and appears to be an excellent scaffold for a research project of this size.

### Literature Review

I will be using the next assignment task to brush up on my Literature Review skills.

## Technical Skills

### Web Development

My creative coding practice has been largely one of learning about full-stack web development.  I currently have several operational iterations of *distributed synthesis*, and continue to improve and learn with every iteration.  Currently I am using [Deno](https://docs.deno.com/), [EventSource](https://developer.mozilla.org/en-US/docs/Web/API/EventSource), [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API), [WebSockets API](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API), [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API), [AudioWorklet](https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet), and [Canvas API](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API), to do the bulk of the technical heavy-lifting.

For most situations, I am able to use [MDN Web Docs](https://developer.mozilla.org/en-US/) for general web-dev technical reference, and the Deno online community has been very generous with helping me understand the nuances of the Deno platform in situations where the [Deno Docs](https://docs.deno.com/) by themselves were not sufficient.

This skillset is probably in some ways, the bottleneck for this project.  This being said, I am enjoying the challenge, and in the end, it is the frustrations caused by tensions between the desires of digital music instrument design, and the viscissitudes of web development, that become the central problematics of *distributed synthesis*, and as such will become fodder for the written articulations of this research.

### Digital Signal Processing

On the computer music side, using AudioWorklet requires some amount of digital signal processing (DSP) knowledge.  I already have a firm understanding of DSP from my undergraduate degree and my practice, and continue to learn more with each iteration.  My existing DSP skillset should be adequate to the task of this research project.


# Works Cited: